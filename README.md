# Multi-model-AI-aggregator

A productionâ€‘grade **Streamlit UI + n8n Orchestration** system that allows users to:

- Run **single model** AI inference
- Run **multiple models in parallel**
- Support **text, image, and audio inputs**
- Display latency + perâ€‘model responses in a clean UI

This project integrates:
- **2 Large Language Models:** GPTâ€‘4o, GPTâ€‘4oâ€‘mini
- **2 Multimodal Models:** Whisper (audio â†’ text), GPTâ€‘4o Vision (image analysis)

---

## ğŸš€ Features

### âœ… Streamlit Frontend
- Select models (LLM + multimodal)
- Choose input type (text / image / audio)
- Upload files (image/audio)
- Enter text prompt
- Clean and modern dark UI
- Hidden webhook URL (secured via environment variable)
- Response cards with model name + latency

### âœ… n8n Backend Orchestrator
- Webhook endpoint for receiving UI requests
- Extracts prompt, models, and input type
- Splits model array into **parallel execution branches**
- Routes requests dynamically using Switch Router
- Executes OpenAI models
- Formats each model output
- Aggregates everything into a final JSON array
- Returns response back to Streamlit

---

## ğŸ—ï¸ System Architecture
```
Streamlit UI â†’ API Layer (Webhook POST) â†’ n8n Orchestration
         â†’ Split Models â†’ Route â†’ Execute Models in Parallel
         â†’ Format â†’ Aggregate â†’ Respond â†’ UI Results Panel
```

### Components
- **API Layer:** Streamlit â†’ n8n webhook
- **Orchestration Layer:** request extraction, model routing, parallel execution
- **Model Adapters:** GPTâ€‘4o, GPTâ€‘4oâ€‘mini, Whisper, GPTâ€‘4o Vision
- **Storage (optional):** Redis for caching
- **Logging:** n8n execution logs + Streamlit console logs

---

## ğŸ”„ Request Flow

### **Single Model Mode**
```
UI â†’ Webhook â†’ Extract Request â†’ Route Model â†’ Execute â†’ Format â†’ Aggregate â†’ UI
```

### **Multiâ€‘Model Parallel Mode**
```
UI â†’ Webhook â†’ Extract Request â†’ Split Models
    â†’ Branch A (GPTâ€‘4o)
    â†’ Branch B (GPTâ€‘4oâ€‘mini)
    â†’ Branch C (Whisper)
    â†’ Branch D (Vision)
All branches â†’ Format â†’ Aggregate â†’ UI
```

---

## ğŸ“¦ Project Structure
```
/streamlit-app
â”‚â”€â”€ app.py                   # Frontend UI
â”‚â”€â”€ assets/                  # Uploaded files (optional)

/n8n-workflow
â”‚â”€â”€ Multi-Model Aggregator.json  # Full workflow export

/docs
â”‚â”€â”€ System_Architecture_Document.docx
```

---

## âš™ï¸ Setup Instructions

### **1. Install dependencies**
```bash
pip install streamlit requests python-dotenv
```

### **2. SetWebhook URL (Secure)**
In your terminal:
```bash
export N8N_WEBHOOK_URL="https://your-domain.app.n8n.cloud/webhook/multi"
```
Windows (PowerShell):
```powershell
setx N8N_WEBHOOK_URL "https://your-domain.app.n8n.cloud/webhook/multi"
```

### **3. Run Streamlit App**
```bash
streamlit run app.py
```

---

## ğŸ§  Models Supported
| Model | Type | Purpose |
|-------|-------|---------|
| GPTâ€‘4o | LLM | General reasoning, text generation |
| GPTâ€‘4oâ€‘mini | LLM | Fast, lightweight responses |
| Whisper | Audio â†’ Text | Speech transcription |
| GPTâ€‘4o Vision | Image â†’ Text | Image understanding |

---

## ğŸ“ˆ Scaling Strategy
- Streamlit is stateless â†’ horizontally scalable
- n8n workflows can run in distributed mode
- Parallel execution builtâ€‘in via Split node
- Add Redis for prompt caching
- Add RabbitMQ for longâ€‘running multimodal jobs

---

## ğŸ” User Management Strategy
- Add JWT / API keys for authentication
- Perâ€‘user model access rules
- Rate-limiting via n8n Rate Limit node
- Logging & usage analytics via Postgres + n8n

---

## ğŸ›¡ï¸ Uptime & Monitoring
- n8n execution logs for debugging
- Prometheus + Grafana integration
- Autoâ€‘restart workflows on failure
- Graceful degradation: failed model doesn't block others

---

## ğŸ“¬ Output Example
```json
{
  "responses": [
    { "model": "gpt4o", "response": "Hello!", "latencyMs": 1240 },
    { "model": "whisper", "response": "Transcribed text...", "latencyMs": 1790 }
  ]
}
```

---

## ğŸ¤ Contribution
Feel free to fork and enhance this multiâ€‘model inference orchestrator.

---


## ğŸ’¬ Need help?
Just ask â€” happy to help you extend this architecture further!
